# -*- coding: utf-8 -*-
"""Modelo_Metricas.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MgMzcXGcd-0dFcCBEuanFPU9YY6w-MpE
"""

#Vincula Colab con Drive (monta el Drive en la máquina virtual que nos provee Google)
from google.colab import drive

drive.mount('/content/DRIVE')

"""#LIBRERIAS"""

#Importo librerias
import pandas as pd
import numpy as np

from sklearn import preprocessing
from sklearn import tree
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV

"""#OBTENCIÓN DEL DATA SET"""

#Lee el csv y lo convierte a un df de pandas
path = '/content/DRIVE/MyDrive/2 - CDIA/CDIA/PPT2/train.csv'
dataset_crudo = pd.read_csv(path)
dataset_crudo

"""#**METRICAS DT**"""

random_forest_accuracy = accuracy_score(Target_test, random_forest_prediction)
decision_tree_accuracy = accuracy_score(Target_test, decision_tree_prediction)

random_forest_accuracy

decision_tree_accuracy

plt.figure(figsize=(10,5))
ax = plt.subplot(1,2,1)
sns.heatmap(confusion_matrix(Target_test, random_forest_prediction), annot=True, fmt="g",  cmap="YlOrRd", cbar=False)
ax.set_xlabel('Prediction')
ax.set_ylabel('Target')
ax.set_title(f"Random Forest (Acc: {random_forest_accuracy:.4f})")
ax = plt.subplot(1,2,2)
sns.heatmap(confusion_matrix(Target_test, decision_tree_prediction), annot=True, fmt="g",  cmap="YlOrRd", cbar=False)
ax.set_xlabel('Prediction')
ax.set_ylabel('Target')
ax.set_title(f"Decision Tree (Acc: {decision_tree_accuracy:.4f})")

#Porque el random forest dio los mejores resultados vemos la importancia de los atributos para este modelo
importances = list(random_forest.feature_importances_)
input_list = list(input.columns)

feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(input_list,importances)]
feature_importances = sorted(feature_importances, key= lambda x: x[1], reverse = True)
[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances ];

plt.figure(figsize=(50,50))
_ = tree.plot_tree(random_forest.estimators_[0], feature_names=input.columns, filled=True, fontsize=18)